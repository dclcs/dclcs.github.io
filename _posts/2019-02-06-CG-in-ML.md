---
title: "图形深度学习 ML BASICS(II)"
author: dcl
categoies: CG
CreateTime: 2019-02-06 17:23:3 +0800
date: 2019-02-06 17:23:3 +0800

---
来自Siggraph

<!--more-->

##### 神经网络训练：旧和新的技巧
- Old
    - 反向传播
        - 训练目标
            - 我们的网络实施是一个参数化函数<br>$f_\theta: \mathbb X \to \mathbb Y$, $\widehat y = f(x;\theta)$
            - 在训练过程中，我们寻找一个参数最小化损失函数:${min}_\theta L_f(\theta)$
            - 例子：L2 regression loss
        - 梯度
            - 前向传播
            - 反向传播
    - 随机梯度、动量、权重延迟（`weight decay`）
- New
    - Dropout
    - Relu
    - Batch Norm(alization), GroupNorm, Spectral Normalization
    - Res(idual)Net(work)

