---
title: 论文《 Pixel2Mesh:Generating 3D Mesh Models from Single RGB Images》
date: 2019-07-13 22:03:15
description: 3D Object Reconstruction
categories:
 - 3D Object Reconstruction
tags: 
- 3D Object Reconstruction
---

### Method
####  Graph-based Convolution


一个3D的Mesh可以看成点、边和面的集合。可以表示成$\mathcal M =(\mathcal V,\mathcal \varepsilon,\mathbf F)$,
其中 $\mathcal V = \\{v_i\\}_{i=1}^N$ 为`mesh`中 $N$ 个点的集合;
$\varepsilon = \\{e_i\\}_{i=1}^E$ 为边的集合;
$\mathbf F=\\{f_i\\}_{i=1}^N$为每个点上的`特征`的集合.

在一个不规则的图上基于图卷积的定义为：

$$f_p^{l+1} = w_0f_p^l + \sum_{q \in \mathcal N(p)}w_1f_q^l$$

其中，$f_p^l \in R^{d_l}$,$f^{l+1}_p \in R^{d_l+1}$ 分别点$p$在卷积前后的特征向量；$\mathcal N(p)$ 为点 $p$  的相邻的点；$w_0$和$w_1$是需要学习到的参数，其`shape`为$d_l \times d_{l+1}$;

在这篇文章中，特征向量$f_p$为**点的3D坐标**、**`feature encoding 3D shape`**和**输入的彩色图片的特征**（如果存在的话）。

####  System Overview

![](https://raw.githubusercontent.com/dclcs/dclcs.github.io/master/_posts/thesis/pix2mesh-1.png)

整个框架包含两个分支：一个图片特征网络和一个级联的`mesh`变形网络。

图片特征网络是一个2D 的CNN，从输入的图形中提取`perceputal feature`；`perceputal feature`是用来让`mesh`变形网络不断进行变形，从一个椭圆的网格到理想状态下的网格。

级联的`mesh`变形网络是一个`GCN`，包含3个`deformation block`和两个`graph unpooling layer`。每个`deformation block`的输入为表示当前`mesh`的图，输出为新的点的位置和特征。而`graph unpooling layers`会点的个数，这是因为为了增加处理细节的能力同时保证`mesh`的拓扑结构。

使用的损失函数包括3个：`Surface normal loss`、`Laplacian regularization loss`、`Edge length loss`

####  Initalize ellipsoid

椭球`mesh`位于相机前0.8m处，并且三个轴的大小为0.2m,0.2m,0.4m;并且包含156个点


####  Mesh deformation block

![](https://raw.githubusercontent.com/dclcs/dclcs.github.io/master/_posts/thesis/pix2mesh-2.png)

为了产生图片中物体的`mesh`，`deformation block`需要输入图片的池化的特征（$\mathbf P$）。$\mathbf C_{i-1}$代表当前`mesh`点的位置。$\mathbf F_{i-1}$代表当前`mesh`的特征。

**Perceptual feature pooling layer**
给定一个点的3D坐标，使用相机的内在参数计算其在图片平面上的2D投影，然后用双线性插值（`bilinear interpolation`）`pool the feature from four nearby pixels`。一般说来，`perceptual feature`是将`conv3_3`、`conv4_3`和`conv5_3`的特征连接起来，最终得到的结果为1280D；然后与128D的输入的`mesh`的3D 特征连接起来，总共的为1408D向量。

**G-ResNet**
输入为1408D的向量。在整个网络架构中，G-ResNet有同样的架构，由14个`graph residual`卷积层包含128个`channel`组成。输出为128D的3D 特征向量和3D 点的坐标。

####  Graph unpooling layer

![](https://raw.githubusercontent.com/dclcs/dclcs.github.io/master/_posts/thesis/pix2mesh-3.png)

上采样层的作用是为了增加`GCNN`中点的个数。一个直接的方法是在每一个三角形中添加一个点（基于面）。然而，这会导致点的不平衡（`imbalanced vertex degree`），如每个点连接的边的个数。受到图形学中算法的启发，增加的点为每条边的中点。

#### Losses

使用`Chamfer Loss`来限制`mesh`点的位置；`noraml loss`来使得表面法向量的连续性；`laplacian regularization`来保持相邻点的相对位置；`edge length regularization`避免异常值。

**Chamfer loss**
`Chamfer loss`是用来测量两个集合间的距离：$l_c=\sum_p\min_q ||p-q||_2^2 + \sum_q\min_p||p-q||_2^2$

**Normal loss**
$l_n=\sum_p\sum_{q=arg \min_q(||p-q||^2_2)}||<p -\mathcal k, \mathbf n_q>||^2_2$ , s.t $\mathcal k \in \mathcal N(p)$，其中$q$为离$p$最近的点。

**Regularization**


*Laplacian regularization* 对每一个点$p$定义拉普拉斯坐标:$\delta_p = p - \sum_{k \in \mathcal N(p)} \frac{1}{||\mathcal N(p)||}\mathcal k$;那么，`Laplacian regularization`为$l_{lap} = \sum_p||\delta_p^{'} - \delta_p||_2^2$，其中$\delta_p^{'}$和$\delta_p$分别为通过`deformation block`前后的坐标。


*Edge Length regularization* $l_{loc}=\sum_p\sum_{\mathcal k \in \mathcal N(p)}||p - \mathcal k||_2^2$



总的损失函数为：$l_{all} = l_c + \lambda_1 l_n + \lambda_2 l_{lap} + \lambda_3 l_{loc}$